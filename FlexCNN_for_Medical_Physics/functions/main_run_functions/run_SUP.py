import os
import time
import torch
import pandas as pd
from torch.utils.data import DataLoader

from classes.generators import Generator
from classes.dataset import NpArrayDataSet
from functions.helper.timing import display_times
from functions.helper.metrics import calculate_metric, SSIM, MSE, custom_metric, reconstruct_images_and_update_test_dataframe, update_tune_dataframe
from functions.helper.reconstruction_projection import reconstruct
from functions.helper.display_images import show_single_unmatched_tensor, show_multiple_matched_tensors
from functions.helper.weights_init import weights_init
from FlexCNN_for_Medical_Physics.functions.helper.displays_and_reports import compute_display_params, get_tune_session


def run_SUP(config, paths, settings):
    """
    Train, test, or visualize a supervisory-loss network using explicit dicts.
    """
    # Dataset slicing controls
    offset = settings.get('offset', 0)
    num_examples = settings.get('num_examples', -1)
    sample_division = settings.get('sample_division', 1)
    print('Dataset offset:', offset)
    print('Dataset num_examples:', num_examples)
    print('Dataset sample_division:', sample_division)

    # Compute batch_size and display_step using helper (with integer rounding)
    batch_size, display_step = compute_display_params(config, settings)

    # Initialize Ray Tune session if available
    session = get_tune_session()

    # Core settings
    run_mode = settings['run_mode']
    device = settings['device']
    train_SI = config['train_SI']
    image_size = config['image_size']
    sino_size = config['sino_size']
    image_channels = config['image_channels']
    sino_channels = config['sino_channels']
    augment = settings.get('augment', False)
    shuffle = settings.get('shuffle', True)
    show_times = settings.get('show_times', False)
    visualize_batch_size = settings.get('visualize_batch_size', 9)
    num_epochs = settings.get('num_epochs', 1)
    load_state = settings.get('load_state', False)
    save_state = settings.get('save_state', False)
    checkpoint_path = paths.get('checkpoint_path', None)
    tune_dataframe_path = paths.get('tune_dataframe_path', None)
    tune_dataframe_fraction = settings.get('tune_dataframe_fraction', 1.0)
    tune_max_t = settings.get('tune_max_t', 0)

    # Loss and scales
    sup_criterion = config['sup_criterion']
    scale = config['SI_scale'] if train_SI else config['IS_scale']

    # Tuning/Test specific initializations
    if run_mode == 'test':
        test_dataframe = pd.DataFrame({'MSE (Network)' : [],  'MSE (FBP)': [],  'MSE (ML-EM)': [], 'SSIM (Network)' : [], 'SSIM (FBP)': [], 'SSIM (ML-EM)': []})

    if run_mode == 'tune' and tune_dataframe_path is not None:
        # Create or restore tuning dataframe
        try:
            tune_dataframe = pd.read_csv(tune_dataframe_path)
        except Exception:
            tune_dataframe = pd.DataFrame({'SI_dropout': [], 'SI_exp_kernel': [], 'SI_gen_fill': [], 'SI_gen_hidden_dim': [], 'SI_gen_neck': [], 'SI_layer_norm': [], 'SI_normalize': [], 'SI_pad_mode': [], 'batch_size': [], 'gen_lr': [], 'num_params': [], 'mean_CNN_MSE': [], 'mean_CNN_SSIM': [], 'mean_CNN_CUSTOM': []})
            tune_dataframe.to_csv(tune_dataframe_path, index=False)

    # Model and optimizer
    if train_SI:
        gen = Generator(config=config, gen_SI=True, input_size=sino_size, input_channels=sino_channels, output_channels=image_channels).to(device)
    else:
        gen = Generator(config=config, gen_SI=False, input_size=image_size, input_channels=image_channels, output_channels=sino_channels).to(device)

    gen_opt = torch.optim.Adam(gen.parameters(), lr=config['gen_lr'], betas=(config['gen_b1'], config['gen_b2']))

    # Data loader
    dataloader = DataLoader(
        NpArrayDataSet(image_path=paths['image_path'], sino_path=paths['sino_path'], config=config,
                       image_size=image_size, image_channels=image_channels, sino_size=sino_size, sino_channels=sino_channels,
                       augment=augment, offset=offset, num_examples=num_examples, sample_division=sample_division),
        batch_size=batch_size,
        shuffle=shuffle
    )

    # Checkpoint handling
    if load_state:
        checkpoint = torch.load(checkpoint_path)
        gen.load_state_dict(checkpoint['gen_state_dict'])
        gen_opt.load_state_dict(checkpoint['gen_opt_state_dict'])
        if run_mode in ('test', 'visualize'):
            gen.eval()
            start_epoch = 0
            end_epoch = 1
            batch_step = 0
        else:  # train
            start_epoch = checkpoint['epoch']
            end_epoch = num_epochs
            batch_step = checkpoint['batch_step']
    else:
        gen = gen.apply(weights_init)
        start_epoch = 0
        batch_step = 0
        end_epoch = num_epochs

    # Running metrics
    mean_gen_loss = 0
    mean_CNN_SSIM = 0
    mean_CNN_MSE = 0
    mean_CNN_CUSTOM = 0
    report_num = 1

    # Timing
    time_init_full = time.time()
    time_init_loader = time.time()

    # Epoch loop
    for epoch in range(start_epoch, end_epoch):
        for sino_ground, sino_ground_scaled, image_ground, image_ground_scaled in iter(dataloader):
            # Times
            _ = display_times('loader time', time_init_loader, show_times)
            time_init_full = display_times('FULL STEP TIME', time_init_full, show_times)

            # Inputs/targets
            if train_SI:
                target = image_ground_scaled
                input_ = sino_ground_scaled
            else:
                target = sino_ground_scaled
                input_ = image_ground_scaled

            # Forward/optimize
            if run_mode in ('tune', 'train'):
                time_init_train = time.time()
                gen_opt.zero_grad()
                CNN_output = gen(input_)
                if run_mode == 'train' and torch.sum(CNN_output[1, 0, :]) < 0:
                    print('PIXEL VALUES SUM TO A NEGATIVE NUMBER. IF THIS CONTINUES FOR AWHILE, YOU MAY NEED TO RESTART')
                gen_loss = sup_criterion(CNN_output, target)
                gen_loss.backward()
                gen_opt.step()
                mean_gen_loss += gen_loss.item() / display_step
                _ = display_times('training time', time_init_train, show_times)
            else:
                CNN_output = gen(input_).detach()

            batch_step += 1

            # Metrics and reconstructions
            time_init_metrics = time.time()
            if run_mode in ('tune', 'train'):
                mean_CNN_SSIM += calculate_metric(target, CNN_output, SSIM) / display_step
                mean_CNN_MSE += calculate_metric(target, CNN_output, MSE) / display_step
                time_init_custom = time.time()
                mean_CNN_CUSTOM += custom_metric(target, CNN_output) / display_step
                _ = display_times('Custom metric time', time_init_custom, show_times)

            if run_mode == 'test':
                test_dataframe, mean_CNN_MSE, mean_CNN_SSIM, mean_FBP_MSE, mean_FBP_SSIM, mean_MLEM_MSE, mean_MLEM_SSIM, FBP_output, MLEM_output = \
                    reconstruct_images_and_update_test_dataframe(input_, image_size, CNN_output, image_ground_scaled, test_dataframe, config)

            if run_mode == 'visualize':
                FBP_output = reconstruct(input_, config, image_size=image_size, recon_type='FBP')
                MLEM_output = reconstruct(input_, config, image_size=image_size, recon_type='MLEM')

            _ = display_times('metrics time', time_init_metrics, show_times)

            # Reporting / visualization
            if batch_step % display_step == 0:
                time_init_visualization = time.time()
                example_num = batch_step * batch_size

                if run_mode == 'tune' and session is not None:
                    session.report({'MSE': mean_CNN_MSE, 'SSIM': mean_CNN_SSIM, 'CUSTOM': mean_CNN_CUSTOM, 'example_number': example_num, 'batch_step': batch_step, 'epoch': epoch})
                    if tune_dataframe_path is not None and int(tune_dataframe_fraction * tune_max_t) == report_num:
                        tune_dataframe = update_tune_dataframe(tune_dataframe, tune_dataframe_path, gen, config, mean_CNN_MSE, mean_CNN_SSIM, mean_CNN_CUSTOM)
                    report_num += 1

                if run_mode == 'train':
                    print('================Training===================')
                    print(f'CURRENT PROGRESS: epoch: {epoch} / batch_step: {batch_step} / image #: {example_num}')
                    print(f'mean_gen_loss: {mean_gen_loss}')
                    print(f'mean_CNN_MSE : {mean_CNN_MSE}')
                    print(f'mean_CNN_SSIM: {mean_CNN_SSIM}')
                    print(f'mean-CNN_CUSTOM {mean_CNN_CUSTOM}')
                    print('===========================================')
                    print('Last Batch MSE: ', calculate_metric(target, CNN_output, MSE))
                    print('Last Batch SSIM: ', calculate_metric(target, CNN_output, SSIM))
                    print('Input:')
                    show_single_unmatched_tensor(input_[0:9])
                    print('Target/Output:')
                    show_multiple_matched_tensors(target[0:9], CNN_output[0:9])

                if run_mode == 'test':
                    print('==================Testing==================')
                    print(f'mean_CNN_MSE/mean_MLEM_MSE/mean_FBP_MSE : {mean_CNN_MSE}/{mean_MLEM_MSE}/{mean_FBP_MSE}')
                    print(f'mean_CNN_SSIM/mean_MLEM_SSIM/mean_FBP_SSIM: {mean_CNN_SSIM}/{mean_MLEM_SSIM}/{mean_FBP_SSIM}')
                    print('===========================================')
                    print('Input')
                    show_single_unmatched_tensor(input_[0:9])
                    print('Target/Output/MLEM/FBP:')
                    show_multiple_matched_tensors(target[0:9], CNN_output[0:9], MLEM_output[0:9], FBP_output[0:9])

                if run_mode == 'visualize':
                    visualize_offset = settings.get('visualize_offset', 0)
                    if visualize_batch_size == 120:
                        print(f'visualize_offset: {visualize_offset}, Image Number (batch_step*120): {batch_step*120}')
                        show_single_unmatched_tensor(target, grid=True, cmap='inferno', fig_size=1)
                    else:
                        print('Input:')
                        show_single_unmatched_tensor(input_[0:visualize_batch_size])
                        print('Target/ML-EM/FBP/Output:')
                        show_multiple_matched_tensors(target[0:visualize_batch_size], MLEM_output[0:visualize_batch_size], FBP_output[0:visualize_batch_size], CNN_output[0:visualize_batch_size])

                if save_state:
                    print('Saving model!')
                    torch.save({'epoch': epoch, 'batch_step': batch_step, 'gen_state_dict': gen.state_dict(), 'gen_opt_state_dict': gen_opt.state_dict()}, checkpoint_path)

                # Reset running stats
                mean_gen_loss = 0
                mean_CNN_SSIM = 0
                mean_CNN_MSE = 0
                mean_CNN_CUSTOM = 0
                _ = display_times('visualization time', time_init_visualization, show_times)

            # Reset loader timer
            time_init_loader = time.time()

    # Save final state (training)
    if save_state:
        print('Saving model!')
        torch.save({'epoch': epoch + 1, 'batch_step': batch_step, 'gen_state_dict': gen.state_dict(), 'gen_opt_state_dict': gen_opt.state_dict()}, checkpoint_path)

    if run_mode == 'test':
        return test_dataframe
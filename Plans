Well I spent two hours working on a plan with you and then the computer froze right before I was about to review the diffs. Let's see if we can do this again more efficiently. These three functions (#train_test_visualize_SUP, #train_test_CYCLE, #train_test_GAN) are found in their respective files in #file:main_run_functions . These all make use of a great number of global variables that were present in a Jupyter notebook. Now that these functions have been moved into a python package (#file:FlexCNN_for_Medical_Physics ) they no longer have access to those global variables. Instead, I'd like to explicitly pass them dictionaries. The variables in the functions will then be replaced with dictionary lookups. The dictionaries that will be passed are constructed in #construct_config and #setup_run_paths (both in #file:construct_dictionaries.py ).  We need to expand these dictionary construction functions so they contain the key-value pairs, one for each of the global variables we will replace. Variables relating to network architecture should be placed in config, paths should be in the paths dictionary and everything else in config. A Jupyter notebook (#file:stitching_notebook.py) that calls these constrution functions will need to be updated as well. While we're at it, let's also clean up some of the code in #test_train_visualize. Some of the code surrounding this bit (display_step = tune_iter_per_report*batch_mult) is used to ensure that RayTune is updated at a constant number of training examples, regardless of batch size. Let's alter the code so that if running with tune_even_reporting==True, the number of training examples per report is specified and the code figures out how many batches should be run between reports.